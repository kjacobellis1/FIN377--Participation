{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a list of URLs for S&P 500 Firms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests_html #easier than writing it on the Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from requests_html import HTMLSession #HTML Session is how it opens pages \n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "session = HTMLSession()\n",
    "r=session.get(url)\n",
    "r.url\n",
    "#we want the links!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.html.links #all the relative links.... you cant \"click on them\"\n",
    "r.html.absolute_links #all of them \"can click on these \"\n",
    "\n",
    "# get the table from the website\n",
    "\n",
    "r.html.find('table') # gives two tables with different id's... but we only want one\n",
    "r.html.find('table')[0] #either of these work\n",
    "table= r.html.find('#constituents')[0]\n",
    "table.html #print html\n",
    "table.text #print the text \n",
    "\n",
    "\n",
    "#blunt force the table \n",
    "table.absolute_links  #extracts all the URLs from the table.... still too many, and can't \"filter\" them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's loop over the rows\n",
    "\n",
    "table.find('tr')[0].text #gives a list of rows, shows that the first row is a header (which we dont want)\n",
    "table.find('tr')[1].text #3M is the company in the first row!\n",
    "\n",
    "table_rows=table.find('tr')\n",
    "\n",
    "colinks=[] #creating an empty frame to store this data in \n",
    "for row in table_rows[1:]:\n",
    "    a_link= list(row.find('td')[1].absolute_links)[0] #hyperlinks the rows\n",
    "    colinks.append(a_link)\n",
    "len(colinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's clean this up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests_html import HTMLSession #HTML Session is how it opens pages \n",
    "\n",
    "#open page\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "session = HTMLSession()\n",
    "r=session.get(url)\n",
    "\n",
    "#grab the URLs\n",
    "table= r.html.find('#constituents')[0]\n",
    "table_rows=table.find('tr')\n",
    "colinks=[] #creating an empty frame to store this data in \n",
    "for row in table_rows[1:]:\n",
    "     colinks.append(list(row.find('td')[1].absolute_links)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-695b612be966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msearch_itunes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'billie eilish'\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# one search at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0msearch_itunes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'father john misty'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# \"another one\" - dj khaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-695b612be966>\u001b[0m in \u001b[0;36msearch_itunes\u001b[0;34m(search_term)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msearch_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'term'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msearch_term\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "def search_itunes(search_term):\n",
    "    '''Simplified iTunes search'''\n",
    "    \n",
    "    base_url = 'https://itunes.apple.com/search'\n",
    "    search_parameters = {'term': search_term}\n",
    "    \n",
    "    r = requests.get(base_url, params = search_parameters)\n",
    "    \n",
    "    results_df = pd.DataFrame(r.json()['results'])\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "search_itunes('billie eilish')      # one search at a time\n",
    "search_itunes('father john misty') # \"another one\" - dj khaled\n",
    "\n",
    "artists = ['billie eilish','father john misty'] # you can loop over them!\n",
    "\n",
    "# download the results and save locally\n",
    "for artist in artists:\n",
    "    df = search_itunes(artist)\n",
    "    # you could do anything with the results here\n",
    "    # a good idea in many projects: save the webpage/search results\n",
    "    # even better: add the saving function inside the \"search_itunes\" fcn\n",
    "    # but this is just a toy illustration, so nothing happens\n",
    "    print(len(df)) \n",
    "    \n",
    "# LATER, you will want to analyze those files. Just loop over the files again:\n",
    "for artist in artists:\n",
    "    # load the saved file\n",
    "    # call a function you wrote to parse one file\n",
    "    # do something with the output from the parser\n",
    "    # but this is just a toy illustration, so nothing happens    \n",
    "    pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
