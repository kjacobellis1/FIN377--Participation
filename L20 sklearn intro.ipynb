{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset loader\n",
    "from sklearn import datasets\n",
    "\n",
    "# model training and evalutation utilities \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold # this is one way to generate folds\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# toy data\n",
    "X,y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What you should learn/be aware of based on this lecture\n",
    "Key sklearn functions:\n",
    "\n",
    "train_test_split\n",
    "cross_validate\n",
    "Fold generators: KFold and StratifiedKFold\n",
    "Scoring functions per last lecture and how to pass to cross_validate\n",
    "How to compare different models by looping over them with cross_validate, GridSearchCV, or RandomizedSearchCV\n",
    "Not covered today but you should check out:\n",
    "\n",
    "confusion_matrix and classification_report (helpful to evaluate models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple \"split, train, evaluate\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "# ignore the model I choose here, its not important what\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X1, y1) # fit on the \"training data\" X1 and  y1\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2) # using X2 (out-of-sample data), predict y2\n",
    "accuracy_score(y2, y2_model) # see how close y2 is to prediction (fraction of all pred that are exactly right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to do k-fold? It's like repeating the above. In pseudo code, it looks like:\n",
    "Break the X and y data into $k$ subsamples\n",
    "For each subsample, fit the model, predict OOS, score predictions, and save those\n",
    "Ok?\n",
    "\n",
    "## K-Fold in Python: The explicit way, and the wrapped way\n",
    "Watch me do the explicit way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the wrapper below! We are going to see how to use that function to:\n",
    "\n",
    "try multiple models\n",
    "try different sets of X variables\n",
    "try different ways to specific folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00120187, 0.00051403, 0.00052929, 0.00082898, 0.00038576]),\n",
       " 'score_time': array([0.00237322, 0.00157785, 0.00252175, 0.00181794, 0.00195813]),\n",
       " 'test_score': array([0.93333333, 0.96666667, 0.93333333, 0.93333333, 0.96666667])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the function here\n",
    "cross_validate(model, X,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00114274, 0.00137186, 0.00044703, 0.00044417, 0.00046325]),\n",
       " 'score_time': array([0.00746536, 0.00851607, 0.00569797, 0.00726891, 0.01046681]),\n",
       " 'test_accuracy': array([0.93333333, 0.96666667, 0.93333333, 0.93333333, 0.96666667]),\n",
       " 'test_r2': array([0.9 , 0.95, 0.9 , 0.9 , 0.95]),\n",
       " 'test_precision_macro': array([0.93333333, 0.96969697, 0.94444444, 0.93333333, 0.96969697])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try here with diff scores\n",
    "\n",
    "cross_validate(model, X,y, scoring=['accuracy','r2','precision_macro'],cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "All the metrics it can compute out of the box are here: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Notice that many of these were discussed in our last lecture!\n",
    "\n",
    "Warning/Note: the metric names on that link and what you put in the scoring dictionary don't seem to match up.\n",
    "\n",
    "### question:\n",
    "using 5 folds, what is the average (across the folders) out-of-sample (training) F1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9464985696564643"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(model,X,y,scoring='f1_macro',cv=5)  ['test_score'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the cross_validate parameters\n",
    "\n",
    "### The model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kathrynjaco08/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00092411, 0.00069594, 0.00079298, 0.0009191 , 0.00194287]),\n",
       " 'score_time': array([0.00124979, 0.00079584, 0.00075817, 0.00123382, 0.00181603]),\n",
       " 'test_score': array([0.96658312, 1.        , 0.93333333, 0.96658312, 1.        ])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the model\n",
    "#by changing the model parameter, you can adjust the type of model and the models parameters\n",
    "cross_validate(SVC(gamma='auto'),X,y,scoring='f1_macro',cv=5)\n",
    "cross_validate(SVC(C=5,gamma='scale'),X,y,scoring='f1_macro',cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question :\n",
    "\n",
    "try to use a regression model, (you can't use f1 on this, so evaluate on r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kathrynjaco08/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.23697114, 0.00094104, 0.00088501]),\n",
       " 'score_time': array([0.00060868, 0.00054765, 0.00045896]),\n",
       " 'test_score': array([0., 0., 0.])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(LinearRegression(),X,y,scoring='r2')  #['score_time'].mean()\n",
    "#using the LinearRegression model from L16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**linear_model submodule contains lots of useful alternate options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv='warn', dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='warn', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example:\n",
    "linear_model.Lasso\n",
    "linear_model.Ridge\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "linear_model.LassoCV() # Returns a Lasso (L1 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.RidgeCV() # Returns a Ridge (L2 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.LogisticRegressionCV() # return best logit model by CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looping over models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up models to try\n",
    "models = []\n",
    "models.append(('svc_1', SVC(gamma='auto') ))\n",
    "models.append(('svc_2', SVC(C=5, gamma='scale') ))\n",
    "models.append(('neighbor1',  KNeighborsClassifier(n_neighbors=1)))\n",
    "\n",
    "models[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_1     : 0.980 (0.016)\n",
      "svc_2     : 0.987 (0.016)\n",
      "neighbor1 : 0.960 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# loop and print\n",
    "for name, model in models:\n",
    "    scores = cross_validate(model, X, y, scoring='accuracy', cv=5)\n",
    "    print('%s: %.3f (%.3f)' % (name.ljust(10), \n",
    "                                   scores['test_score'].mean(), \n",
    "                                   scores['test_score'].std()\n",
    "                                   )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- helps you pick the exact perameters within the model!\n",
    "\n",
    "**gridsearchCV\n",
    "randomizedsearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The X Parameter\n",
    "\n",
    "**You can loop over Xs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a smaller X and a bigger X\n",
    "X_small = X[:,:2] # just first two columns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X3 = poly.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X         :0.960 (0.025)\n",
      "X_small   :0.727 (0.061)\n",
      "X3        :0.947 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# set up Xs to try\n",
    "Xs =[]\n",
    "Xs.append( ('X',X    )    )\n",
    "Xs.append( ('X_small',X_small    )    )\n",
    "Xs.append( ('X3',X3    )    )\n",
    "\n",
    "# loop and print\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "for X_name, X in Xs:\n",
    "    scores = cross_validate(model, X, y, scoring='accuracy',cv=5)\n",
    "    print('%s:%.3f (%.3f)' % (X_name.ljust(10),\n",
    "                             scores['test_score'].mean(),\n",
    "                             scores['test_score'].std()\n",
    "                             )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xs and Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_1     + X         :0.980 (0.016)\n",
      "svc_2     + X         :0.987 (0.016)\n",
      "neighbor1 + X         :0.960 (0.025)\n",
      "svc_1     + X_small   :0.820 (0.058)\n",
      "svc_2     + X_small   :0.813 (0.054)\n",
      "neighbor1 + X_small   :0.727 (0.061)\n",
      "svc_1     + X3        :0.527 (0.077)\n",
      "svc_2     + X3        :0.973 (0.025)\n",
      "neighbor1 + X3        :0.947 (0.016)\n"
     ]
    }
   ],
   "source": [
    "for X_name, X in Xs:\n",
    "    for name, model in models:\n",
    "        scores = cross_validate(model, X, y, scoring='accuracy',cv=5)\n",
    "        print('%s+ %s:%.3f (%.3f)' % (name.ljust(10),\n",
    "                              X_name.ljust(10),\n",
    "                             scores['test_score'].mean(),\n",
    "                             scores['test_score'].std()\n",
    "                             )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV parameter and folds\n",
    "Just watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00077534, 0.00075817, 0.00042486, 0.00038385, 0.00041986]),\n",
       " 'score_time': array([0.00293279, 0.00296998, 0.00177503, 0.00194383, 0.00182223]),\n",
       " 'test_score': array([0.93333333, 0.96666667, 0.93333333, 0.93333333, 0.96666667])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(model, X,y,scoring='accuracy',cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[\"a\", 'a','a','b','b','b','c','c','c'] #silly formatting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0 1 3 4 5 7]                    test: [2 6 8]\n",
      "       ['a', 'a', 'b', 'b', 'b', 'c']         ['a', 'c', 'c']\n",
      "\n",
      "train: [2 3 4 5 6 8]                    test: [0 1 7]\n",
      "       ['a', 'b', 'b', 'b', 'c', 'c']         ['a', 'a', 'c']\n",
      "\n",
      "train: [0 1 2 6 7 8]                    test: [3 4 5]\n",
      "       ['a', 'a', 'a', 'c', 'c', 'c']         ['b', 'b', 'b']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=3)\n",
    "kf=KFold(n_splits=3,shuffle=True,random_state=1) #must give state!\n",
    "\n",
    "for train, test in kf.split(y): #for each fold,\n",
    "    print(\"train: %s test: %s\"  % (str(train).ljust(32), test)) #but here, just show\n",
    "    print(\"       %s       %s\"  % (str([y[j] for j in train]).ljust(32),  [y[j] for j in test]))\n",
    "    print() #blank line\n",
    "    \n",
    "#ffold --> splits it BY INDEX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1 2 4 5 7 8]                    test: [0 3 6]\n",
      "       ['a', 'a', 'b', 'b', 'c', 'c']         ['a', 'b', 'c']\n",
      "\n",
      "train: [0 2 3 5 6 8]                    test: [1 4 7]\n",
      "       ['a', 'a', 'b', 'b', 'c', 'c']         ['a', 'b', 'c']\n",
      "\n",
      "train: [0 1 3 4 6 7]                    test: [2 5 8]\n",
      "       ['a', 'a', 'b', 'b', 'c', 'c']         ['a', 'b', 'c']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "#skf = StratifiedKFold(n_splits=3,shuffle=True,random_state=1) #now random\n",
    "X = y #skf needs an X and y variable\n",
    "\n",
    "for train, test in skf.split(X,y): #for each fold,\n",
    "    print(\"train: %s test: %s\"  % (str(train).ljust(32), test)) #but here, just show\n",
    "    print(\"       %s       %s\"  % (str([y[j] for j in train]).ljust(32),  [y[j] for j in test]))\n",
    "    print() #blank line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kf        : 0.000 (0.000)\n",
      "kf_rand   : 0.947 (0.025)\n",
      "skf_3     : 0.967 (0.033)\n",
      "skf_3_rand: 0.960 (0.016)\n",
      "skf_5     : 0.960 (0.025)\n"
     ]
    }
   ],
   "source": [
    "#reload the X and y variables (we just overwrote)\n",
    "X,y= datasets.load_iris(return_X_y=True)\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "cross_validate(model, X, y, cv=StratifiedKFold(n_splits=3)   ,  scoring = 'accuracy')\n",
    "\n",
    "#set up folds to try\n",
    "folds=[]\n",
    "folds.append(('kf', KFold(n_splits=3)   ))\n",
    "folds.append(('kf_rand', KFold(n_splits=3,shuffle=True,random_state=1)  ))\n",
    "folds.append(('skf_3', StratifiedKFold(n_splits=3)))\n",
    "folds.append(('skf_3_rand', StratifiedKFold(n_splits=3,shuffle=True,random_state=1)))\n",
    "folds.append(('skf_5', StratifiedKFold(n_splits=5)))\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "#loop and print\n",
    "for fold_name, fold in folds:\n",
    "    scores = cross_validate(model,X,y,cv=fold,scoring='accuracy')\n",
    "    print('%s: %.3f (%.3f)' % (fold_name.ljust(10),\n",
    "                                  scores['test_score'].mean(),\n",
    "                                  scores['test_score'].std()\n",
    "                                  )\n",
    "         )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Links, resources, and next week\n",
    "Only two resources needed\n",
    "\n",
    "- sklearn docs are GREAT https://scikit-learn.org/stable/user_guide.html\n",
    "- Python Data Science Handbook (note some module calls are obsolete, so you might need to update code) https://jakevdp.github.io/PythonDataScienceHandbook/index.html\n",
    "\n",
    "Next week:\n",
    "\n",
    "- preprocessing\n",
    "- data transformations\n",
    "- feasture selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
